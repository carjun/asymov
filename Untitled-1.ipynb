{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[-0.8838,  0.0652, -0.3634],\n",
    "             [-1.1894, -0.0717, -0.0899]])\n",
    "b = torch.tensor([[-0.8838,  0.0652, -0.3634],\n",
    "             [-1.1894, -0.0717, -0.0899]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8838,  0.0652, -0.3634],\n",
       "        [-1.1894, -0.0717, -0.0899],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,torch.tensor([0, 0, 0]).unsqueeze(0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((a,c), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False,  True,  True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,0,1,0,0]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[-1.1773,  0.3129, -0.4569, -0.6201,  0.8288, -0.6680],\n",
    "        [-1.4264,  0.1560, -0.3141, -0.4562,  0.5652, -0.3873]])\n",
    "c = torch.tensor([])\n",
    "\n",
    "c = torch.cat((c,t), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1773,  0.3129, -0.4569],\n",
       "        [-0.6201,  0.8288, -0.6680],\n",
       "        [-1.4264,  0.1560, -0.3141],\n",
       "        [-0.4562,  0.5652, -0.3873]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True],\n",
       "        [ True, False,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False,  True]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(4,-1) <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "next = torch.tensor([[],\n",
    "                     []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tgt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mcat((tgt\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m),next_chars\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)), \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tgt' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cat((tgt.unsqueeze(-2),next_chars.transpose(1,0).unsqueeze(-2)), -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 4, 2, 3],\n",
       "         [4, 2, 0, 3, 1]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = torch.tensor([[0.6125, 1.6125, 4.6125, 2.6125, 3.6125],\n",
    "        [4.6125, 2.6125, 0.6125, 3.6125, 1.6125]])\n",
    "idx = indexes.long()\n",
    "idx, idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_len = torch.tensor([[0,0],\n",
    "                        [1,1], \n",
    "                        [2,2],\n",
    "                        [3,3],\n",
    "                        [4,4]])\n",
    "tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4],\n",
       "        [1, 2],\n",
       "        [4, 0],\n",
       "        [2, 3],\n",
       "        [3, 1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(idx)):\n",
    "    tgt_len[:,i] = tgt_len[:,i][idx[i]]\n",
    "tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]),\n",
       " tensor([[[False],\n",
       "          [False]],\n",
       " \n",
       "         [[False],\n",
       "          [False]],\n",
       " \n",
       "         [[False],\n",
       "          [False]],\n",
       " \n",
       "         [[False],\n",
       "          [False]],\n",
       " \n",
       "         [[False],\n",
       "          [False]]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_padding_mask = torch.tensor([[False],\n",
    "                                 [False]])\n",
    "\n",
    "tgt_padding_mask.shape, tgt_padding_mask.unsqueeze(0).repeat((5,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1, 615],\n",
       "        [  1, 407],\n",
       "        [  1, 380],\n",
       "        [  1, 270],\n",
       "        [  1, 957]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = torch.tensor([[[  1,   1],\n",
    "                     [615, 615]],\n",
    "\n",
    "                    [[  1,   1],\n",
    "                     [407, 385]],\n",
    "\n",
    "                    [[  1,   1],\n",
    "                     [380, 572]],\n",
    "\n",
    "                    [[  1,   1],\n",
    "                     [270, 380]],\n",
    "\n",
    "                    [[  1,   1],\n",
    "                     [957, 784]]])\n",
    "\n",
    "bst_can = torch.tensor([[0, 1, 4, 2, 3],\n",
    "        [4, 2, 0, 3, 1]])\n",
    "\n",
    "# for i in range(len(bst_can)):\n",
    "#     tgt[:]\n",
    "\n",
    "# tgt[:,:,0] = tgt[:,:, 0][bst_can[0]]\n",
    "tgt[:,:, 0]\n",
    "# tgt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial for bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.tensor([[615, 380],\n",
    "                    [615, 784]])\n",
    "\n",
    "# idx.squeeze(-1) in beam[0][-1]\n",
    "torch.equal(idx.squeeze(-1).unsqueeze(0), beam[0][-1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = torch.tensor([[[1,     1],  \n",
    "                      [385, 783]],\n",
    "                     [[1,     1],\n",
    "                      [572, 615]],\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "idx = torch.tensor([[615, 380],\n",
    "                    [615, 784]])\n",
    "# torch.tensor([b[-1] for b in beam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[385, 783],\n",
       "         [572, 615]]),\n",
       " tensor([[615, 615],\n",
       "         [380, 784]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam[:, -1, :], idx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[False, False, False, True],[True, True, False, False]])\n",
    "\n",
    "# Get the first occurrence of false in each row\n",
    "# result = A.nonzero()#[:,1]#.min(dim=1)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "A.long().argmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]),\n",
       " tensor([[0, 0],\n",
       "         [1, 0]]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.stack([(beam[:, -1, :] == idx.T[i]).any(dim=1) for i in range(idx.shape[0])], dim=1).long()\n",
    "argmin = A.argmin(1)\n",
    "argmin, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_index = torch.stack([torch.arange(A.shape[0]), argmin], dim=1)\n",
    "complete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(idx.T, beam[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2],[2,4]])\n",
    "B = torch.tensor([[2,2],[5,6]])\n",
    "\n",
    "# Create a boolean mask indicating if each row of A has a common element with each row of B\n",
    "mask = torch.stack([(A == B[i]).any(dim=1) for i in range(B.shape[0])], dim=1)\n",
    "\n",
    "# Get the indices of the rows in A that have a common element with each row of B\n",
    "indices = (mask.nonzero()[:,0]).unique()\n",
    "\n",
    "# Get the rows of A that have a common element with each row of B\n",
    "result = A[indices,:]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diverse Selection of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([True, True]), tensor([False, False])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[615, 615]])\n",
    "B = torch.tensor([[615, 934],\n",
    "                  [615, 572]])\n",
    "\n",
    "[(A == B.T[i]).any(dim=0) for i in range(B.T.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A == B.T[0]).a(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [(A == B[i]).any(dim=1) for i in range(B.shape[0])]\n",
    "A = torch.stack([(A == B.T[i]).any(dim=0) for i in range(B.T.shape[0])], dim=1).long()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmin = A.argmin(1)\n",
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([1, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(A.shape[0]), argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_index = torch.stack([torch.arange(A.shape[0]), argmin], dim=1)\n",
    "complete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True],\n",
       "        [False,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [5, 4]])\n",
    "b = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "torch.eq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(beam[0][-1].unsqueeze(0), idx.squeeze(-1).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([615., 615.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[615],\n",
    "                  [615]])\n",
    "\n",
    "b = torch.tensor([[  1,   1],\n",
    "                  [615, 615]])\n",
    "\n",
    "# torch.cat((a,b))\n",
    "temp = torch.tensor([])\n",
    "\n",
    "torch.cat((temp, a.squeeze()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[615, 615],\n",
       "        [615, 615]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a.squeeze(1).unsqueeze(0), a.squeeze(1).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   1],\n",
       "        [615, 615],\n",
       "        [615, 615]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((b, a.squeeze(1).unsqueeze(0)), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beam as batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[615, 380, 211, 934, 407],\n",
    "                [615, 934, 407, 270, 380],\n",
    "                [615, 380, 934, 407, 270],\n",
    "                [615, 934, 407, 270, 957],\n",
    "                [615, 380, 270, 407, 777],\n",
    "                [615, 784, 572, 385, 380],\n",
    "                [615, 572, 385, 288, 784],\n",
    "                [615, 784, 784, 385, 288],\n",
    "                [615, 380, 572, 385, 784],\n",
    "                [615, 784, 572, 385, 589]])\n",
    "\n",
    "bol = torch.zeros(a.shape, dtype=torch.bool)\n",
    "bol[:2, 0] = True\n",
    "\n",
    "# for i in range(2, a.shape[0], 2):\n",
    "#     print(i)\n",
    "#     mask_num = (a[i:i+2][:, None] == a[bol].reshape(-1,2).T.unsqueeze(-1)).any(dim=1).long()\n",
    "#     unique_token_idx = torch.argmin(mask_num, axis=1)\n",
    "#     # pdb.set_trace()\n",
    "#     bol[torch.arange(i,i+2), unique_token_idx] = True\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[615, 615]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[bol].reshape(-1,2)#.T.reshape(-1).unsqueeze(0), a[bol].reshape(-1,2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[615, 934, 270, 407, 777]],\n",
       " \n",
       "         [[615, 784, 572, 385, 380]]]),\n",
       " tensor([[[615],\n",
       "          [380]],\n",
       " \n",
       "         [[615],\n",
       "          [934]]]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a[bol].reshape(-1,2).T.unsqueeze(-1), \n",
    "a[4:6][:, None], torch.tensor([[[615], [380]], [[615], [934]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin((a[4:6][:, None] == torch.tensor([[[615], [380]], [[615], [934]]])).any(dim=1).long(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[bol].reshape(-1,2).T.unsqueeze(-1) == a[2:4][:, None]\n",
    "bol[[4,5], torch.argmin((a[4:6][:, None] == torch.tensor([[[615], [380]], [[615], [934]]])).any(dim=1).long(), dim=1)+1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin((a[4:6][:, None] == torch.tensor([[[615], [380]], [[615], [934]]])).any(dim=1).long(), dim=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False, False,  True, False, False],\n",
       "        [False, False,  True, False, False]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[615, 934, 407, 270, 380]],\n",
       " \n",
       "         [[615, 572, 385, 288, 784]]]),\n",
       " tensor([[[615]],\n",
       " \n",
       "         [[615]]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[1,6]][:, None], a[bol][:, None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin((torch.tensor([[[615, 934, 407, 270, 380]], [[615, 934, 270, 407, 777]]]) == torch.tensor([[[615], [407]], [[934], [777]]])).any(dim=1).long(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([[[615, 934, 407, 270, 380]], [[615, 934, 270, 407, 777]]]) == torch.tensor([[[615], [407]], [[934], [777]]])).any(dim=1).long()\n",
    "\n",
    "# torch.tensor([[[615], [407]], [[934], [777]]]).shape, torch.tensor([[[615, 934, 407, 270, 380]], [[615, 934, 270, 407, 777]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 2d array\n",
    "# arr = torch.tensor([[1, 2, 3, 4], [4, 5, 6, 7], [7, 8, 9, 10]])\n",
    "a = a[:5]\n",
    "# Get unique elements from each row\n",
    "result = torch.zeros(a.size(0), dtype=torch.long)\n",
    "for i in range(a.size(0)):\n",
    "    unique, indices = torch.unique(a[i, :], return_inverse=True)\n",
    "    result[i] = unique[indices[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding end token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(torch.logical_and(diverse_tokens==320, tgt_len==predictions), i+2, tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([220, 220, 220, 220, 220, 220, 220, 220, 220, 220])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((2,), 220).repeat(5,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_auto(\n",
    "    model,\n",
    "    src,\n",
    "    tgt,\n",
    "    src_mask,\n",
    "    src_padding_mask,\n",
    "    tgt_mask,\n",
    "    tgt_padding_mask,\n",
    "    end_symbol: int,\n",
    "    predictions = 20,\n",
    "    beam_width = 5,\n",
    "    batch_size = 2,    \n",
    "):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pdb.set_trace()           ##\n",
    "\n",
    "        src = src.repeat((1, beam_width))\n",
    "        # src = src.repeat_interleave(beam_width, dim=1)\n",
    "        src_padding_mask = src_padding_mask.repeat((beam_width,1))\n",
    "        # src_padding_mask = src_padding_mask.repeat_interleave(beam_width, dim=0)\n",
    "        tgt = tgt.repeat((1,beam_width))\n",
    "        tgt_padding_mask = tgt_padding_mask.repeat((beam_width, 1))\n",
    "\n",
    "        # pdb.set_trace()           ##\n",
    "\n",
    "        memory = model.encode(src, src_mask, src_padding_mask)  # [Frames, Batches, *]\n",
    "        out = model.decode(tgt, memory, tgt_mask, None, tgt_padding_mask, src_padding_mask)  # [Frames, Batch Size, *]\n",
    "        logits = model.generator(out[-1])\n",
    "\n",
    "        next_probabilities = logits#[-1, :]\n",
    "        probabilities, next_chars = next_probabilities.squeeze().log_softmax(-1).topk(k=beam_width, axis=-1)\n",
    "        \n",
    "        probabilities, next_chars = probabilities[[0,-1],:], next_chars[[0,-1],:]\n",
    "        # pdb.set_trace()           ##\n",
    "        \n",
    "        # tgt = tgt.repeat((1, beam_width))       #repeat BOS  for beam width\n",
    "        # tgt_padding_mask = tgt_padding_mask.unsqueeze(0).repeat((beam_width, 1, 1))\n",
    "\n",
    "        tgt_len = tgt.new_full((batch_size*beam_width, ), predictions)#.repeat((beam_width, 1)) #[beam_width, Batch Size] #same dtype as tgt\n",
    "        \n",
    "        next_token_mask = torch.zeros(next_chars.shape, dtype=torch.bool)\n",
    "        next_token_mask[:batch_size, 0] = True             #first beam decoded acc to highest prob (normal beam search)\n",
    "\n",
    "        for i in range(batch_size, next_chars.shape[0], batch_size):\n",
    "            mask_num = (next_chars[i:i+batch_size][:, None] == next_chars[next_token_mask].reshape(-1,batch_size).T.unsqueeze(-1)).any(dim=1).long()\n",
    "            unique_token_idx = torch.argmin(mask_num, axis=1)\n",
    "            # pdb.set_trace()\n",
    "            next_token_mask[torch.arange(i, i+batch_size), unique_token_idx] = True\n",
    "\n",
    "        next_tokens = next_chars[next_token_mask].reshape(-1,2).T.reshape(-1)\n",
    "        pdb.set_trace()           ##\n",
    "\n",
    "        # tgt = torch.cat((tgt.unsqueeze(-2), next_chars.transpose(1,0).unsqueeze(-2)), -2)      #concat next tokens for each beam (vertically)\n",
    "        tgt = torch.cat((tgt, next_tokens.unsqueeze(0)))\n",
    "\n",
    "        # pdb.set_trace()           ##\n",
    "\n",
    "        # diverse_tokens = torch.tensor([])\n",
    "        # seq_prob = torch.tensor([])\n",
    "\n",
    "        predictions_iterator = range(1, predictions-1)     #1 (0th) prediction already done\n",
    "        for i in predictions_iterator:\n",
    "\n",
    "            tgt_mask = (T.generate_square_subsequent_mask(tgt.size(0))      #size(0) for num of decoded\n",
    "                    .to(tgt.device, dtype=torch.bool))                      #tokens.\n",
    "            pdb.set_trace()\n",
    "            # next_probabilities = torch.tensor([]) # will be containing probabs.(logits) for [batch,1004*beam_width]\n",
    "\n",
    "            tgt_padding_mask = torch.cat([tgt_padding_mask, (tgt_len<=i).unsqueeze(-1)], dim=-1)\n",
    "\n",
    "            for b in range(beam_width):         #if using i, it's continued outside scope of for loop\n",
    "\n",
    "                out_temp = model.decode(tgt, memory, tgt_mask, None, tgt_padding_mask, src_padding_mask)\n",
    "                logits_temp = model.generator(out_temp[-1])\n",
    "\n",
    "                if b == 0:\n",
    "                  # pdb.set_trace()\n",
    "                  probabilities, idx = logits_temp.log_softmax(-1).topk(k=1, axis=-1)    ##\n",
    "\n",
    "                  diverse_tokens = idx.squeeze().unsqueeze(0)\n",
    "                  if i == predictions - 1:\n",
    "                    seq_prob = probabilities.squeeze().unsqueeze(0)\n",
    "\n",
    "                else:\n",
    "                  # pdb.set_trace()\n",
    "\n",
    "                  probabilities, idx = logits_temp.log_softmax(-1).topk(k=b+1, axis=-1)\n",
    "\n",
    "                  unique_mask = torch.stack([(diverse_tokens == idx.T[i]).any(dim=0) for i in range(idx.T.shape[0])], dim=1).long()\n",
    "                  first_unique = unique_mask.argmin(1)                                #in all elements of batch\n",
    "                  # complete_index = torch.stack([torch.arange(unique_mask.shape[0]), first_unique], dim=1)   #containes coordinates -> diverse tokens, dim=0 -> batch_size\n",
    "\n",
    "                  unique_tokens = idx[torch.arange(first_unique.shape[0]), first_unique]      #needs to be checked\n",
    "                  current_token_prob = probabilities[torch.arange(first_unique.shape[0]), first_unique]\n",
    "\n",
    "                  diverse_tokens = torch.cat((diverse_tokens, unique_tokens.unsqueeze(0)))\n",
    "                  if i == predictions - 1:\n",
    "                    seq_prob = torch.cat((seq_prob, current_token_prob.unsqueeze(0)))\n",
    "\n",
    "            tgt_len = torch.where(torch.logical_and(diverse_tokens==end_symbol, tgt_len==predictions), i+2, tgt_len)     #this requires debugging\n",
    "\n",
    "            tgt = torch.cat((tgt, diverse_tokens.unsqueeze(-2)), -2)\n",
    "        \n",
    "        top_b = torch.argmax(seq_prob[1:], axis=0)        #like top-G, but gives top beams for batch elements correspondingly\n",
    "        pdb.set_trace()\n",
    "        return tgt[top_b, :, torch.arange(tgt.size(-1))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d2829036e2bc88c939bf26174c1338eed948a5b3088bd14378c54b2fc44eaba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
